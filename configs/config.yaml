data:
  raw_dir: "data/raw"
  raw_csv: "data/raw/rows.csv"
  processed_dir: "data/processed"
  cache_dir: "data/cache_embeddings"
  outputs_dir: "data/outputs"

models:
  clip_model_name: "openai/clip-vit-base-patch32"

sieve:
  batch_size: 16
  device: "cpu"

  # similarity thresholding
  threshold_method: "iqr"        # "iqr" or "quantile"
  iqr_k: 1.5                     # used if method="iqr"
  quantile_q: 0.05               # used if method="quantile"

  min_category_samples: 8
  global_threshold_method: "quantile"
  global_quantile_q: 0.10

  # âœ… Upgrade 3A: multi-text views + attrs outlier
  enable_multi_text: true

  # bottom-quantile thresholding for sim_attrs (category-wise with fallback)
  attrs_outlier_quantile: 0.05         # flag bottom 5% sim_attrs within category
  attrs_min_category_samples: 8
  attrs_global_quantile: 0.10          # fallback global (bottom 10%)

  enable_gap_probe: true
  gap_outlier_quantile: 0.95
  gap_min_category_samples: 8
  gap_global_quantile: 0.95
  gap_positive_only: true

  enable_color_probe: true
  color_vocab: ["red","blue","green","black","white","yellow","pink","purple","brown","orange","gray"]
  color_margin_threshold: 0.05
  color_min_confidence: 0.30

noise:
  seed: 7
  copies_per_row: 15
  noise_rate: 0.30
  p_swap_image: 0.50
  max_strength: 3
